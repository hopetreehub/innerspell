
'use server';

/**
 * @fileOverview Generates an AI-powered interpretation of a tarot card spread based on a user's question.
 *
 * - generateTarotInterpretation - A function that handles the tarot card interpretation process.
 * - GenerateTarotInterpretationInput - The input type for the generateTarotInterpretation function.
 * - GenerateTarotInterpretationOutput - The return type for the generateTarotInterpretation function.
 */

import {getAI} from '@/ai/genkit';
import {z} from 'genkit';
import { getTarotPromptConfig } from '@/ai/services/prompt-service';
import { getProviderConfig } from '@/lib/ai-utils';
import { getProviderWithFallback } from '@/ai/services/ai-provider-fallback';
import { getCachedInterpretation, setCachedInterpretation } from '@/ai/services/ai-cache-service';
import { retryAICall } from '@/ai/services/ai-retry-service';
import { 
  extractStyleFromQuestion, 
  extractSpreadType, 
  extractCardIds, 
  generateStyledPrompt 
} from '@/ai/services/tarot-style-service';


const GenerateTarotInterpretationInputSchema = z.object({
  question: z.string().describe('The user provided question for the tarot reading, potentially including an interpretation style cue like "(í•´ì„ ìŠ¤íƒ€ì¼: ìŠ¤íƒ€ì¼ ì´ë¦„)".'),
  cardSpread: z.string().describe('The selected tarot card spread (e.g., 1-card, 3-card, custom). Also includes card position names if defined for the spread.'),
  cardInterpretations: z.string().describe('The interpretation of each card in the spread, including its name, orientation (upright/reversed), and potentially its position in the spread. This is a single string containing all card details.'),
  isGuestUser: z.boolean().optional().describe('Whether the user is a guest (not logged in). If true, provide a shorter, teaser interpretation.'),
});
export type GenerateTarotInterpretationInput = z.infer<typeof GenerateTarotInterpretationInputSchema>;

const GenerateTarotInterpretationOutputSchema = z.object({
  interpretation: z.string().describe('The AI-powered interpretation of the tarot card spread.'),
});
export type GenerateTarotInterpretationOutput = z.infer<typeof GenerateTarotInterpretationOutputSchema>;


export async function generateTarotInterpretation(input: GenerateTarotInterpretationInput): Promise<GenerateTarotInterpretationOutput> {
  console.log('[TAROT] ========== GENERATE INTERPRETATION START ==========');
  console.log('[TAROT] Environment check:', {
    NODE_ENV: process.env.NODE_ENV,
    VERCEL: process.env.VERCEL,
    VERCEL_ENV: process.env.VERCEL_ENV,
    timestamp: new Date().toISOString()
  });
  
  return generateTarotInterpretationFlow(input);
}

const generateTarotInterpretationFlow = async (flowInput: GenerateTarotInterpretationInput): Promise<GenerateTarotInterpretationOutput> => {
  // Check cache first
  const cacheKey = {
    question: flowInput.question,
    cardSpread: flowInput.cardSpread,
    cardInterpretations: flowInput.cardInterpretations,
    isGuestUser: flowInput.isGuestUser || false,
  };
  
  const cachedInterpretation = getCachedInterpretation(cacheKey);
  if (cachedInterpretation) {
    console.log('[TAROT] Returning cached interpretation');
    return { interpretation: cachedInterpretation };
  }
  
  console.log('[TAROT] Initializing AI instance...');
  let ai;
  try {
    ai = await getAI();
    console.log('[TAROT] âœ… AI instance obtained successfully');
  } catch (error) {
    console.error('[TAROT] âŒ Failed to get AI instance:', error);
    console.error('[TAROT] Error details:', {
      message: error?.message,
      type: error?.constructor?.name,
      stack: error?.stack
    });
    
    // Vercel í™˜ê²½ì—ì„œ ë” ìì„¸í•œ ì—ëŸ¬ ë©”ì‹œì§€ ì œê³µ
    if (error?.message?.includes('No AI provider API keys')) {
      return { 
        interpretation: 'âš ï¸ AI ì„¤ì • ì˜¤ë¥˜: Vercel í™˜ê²½ë³€ìˆ˜ì— AI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. GOOGLE_API_KEY ë˜ëŠ” OPENAI_API_KEYë¥¼ Vercel Dashboardì—ì„œ ì„¤ì •í•´ì£¼ì„¸ìš”.' 
      };
    }
    
    throw error;
  }
  
  return ai.defineFlow(
    {
      name: 'generateTarotInterpretationFlow',
      inputSchema: GenerateTarotInterpretationInputSchema,
      outputSchema: GenerateTarotInterpretationOutputSchema,
    },
    async (input: GenerateTarotInterpretationInput) => {
    
    try {
      // ìŠ¤íƒ€ì¼ ì •ë³´ ì¶”ì¶œ
      const { styleId, styleName, cleanQuestion } = extractStyleFromQuestion(input.question);
      const spreadType = extractSpreadType(input.cardSpread);
      const cardIds = extractCardIds(input.cardInterpretations);
      
      console.log('[TAROT] Style extracted:', { styleId, styleName, spreadType, cardCount: cardIds.length });
      
      // Try to get the best available provider with automatic fallback
      let providerInfo;
      let model: string;
      let promptTemplate: string;
      let safetySettings: any[];
      
      // ğŸ”´ CRITICAL: Vercel í™˜ê²½ì—ì„œëŠ” í™˜ê²½ë³€ìˆ˜ ê¸°ë°˜ ëª¨ë¸ ìš°ì„  ì‚¬ìš©
      const isVercel = process.env.VERCEL === '1' || process.env.VERCEL_ENV !== undefined;
      const isProduction = process.env.NODE_ENV === 'production';
      
      if (isVercel || isProduction) {
        console.log('[TAROT] Vercel/Production environment detected - using environment-based configuration');
        
        // í™˜ê²½ë³€ìˆ˜ì—ì„œ ì§ì ‘ ëª¨ë¸ ì„¤ì •
        if (process.env.GOOGLE_API_KEY || process.env.GEMINI_API_KEY) {
          model = 'googleai/gemini-1.5-flash-latest';
          providerInfo = { provider: 'googleai', model: 'gemini-1.5-flash-latest' };
          console.log('[TAROT] Using Google AI/Gemini from environment');
        } else if (process.env.OPENAI_API_KEY) {
          model = 'openai/gpt-3.5-turbo';
          providerInfo = { provider: 'openai', model: 'gpt-3.5-turbo' };
          console.log('[TAROT] Using OpenAI from environment');
        } else {
          console.error('[TAROT] No API keys found in environment!');
          throw new Error('No AI API keys configured in Vercel environment');
        }
        
        // ìŠ¤íƒ€ì¼ë³„ í”„ë¡¬í”„íŠ¸ ìƒì„±
        promptTemplate = await generateStyledPrompt(
          styleId,
          spreadType,
          cardIds,
          cleanQuestion,
          input.cardInterpretations
        );
        
        safetySettings = [];
      } else {
        // ê°œë°œ í™˜ê²½ì—ì„œëŠ” ê¸°ì¡´ ë¡œì§ ì‚¬ìš©
        try {
          // First try to get configured provider
          const config = await getTarotPromptConfig();
          providerInfo = { provider: config.model.split('/')[0], model: config.model };
          model = config.model;
          
          // ìŠ¤íƒ€ì¼ë³„ í”„ë¡¬í”„íŠ¸ ìƒì„±
          promptTemplate = await generateStyledPrompt(
            styleId,
            spreadType,
            cardIds,
            cleanQuestion,
            input.cardInterpretations
          );
          
          safetySettings = config.safetySettings;
        } catch (error) {
          console.log('[TAROT] Primary config failed, using fallback system:', error);
          // Use fallback system if primary config fails
          const fallbackInfo = await getProviderWithFallback();
          providerInfo = fallbackInfo;
          model = `${fallbackInfo.provider}/${fallbackInfo.model}`;
          
          // ìŠ¤íƒ€ì¼ë³„ í”„ë¡¬í”„íŠ¸ ìƒì„± (fallbackì˜ ê²½ìš°ë„ ë™ì¼í•˜ê²Œ)
          promptTemplate = await generateStyledPrompt(
            styleId,
            spreadType,
            cardIds,
            cleanQuestion,
            input.cardInterpretations
          );
          
          safetySettings = [];
          
          if (fallbackInfo.fallbackInfo.fallbackUsed) {
            console.log('[TAROT] Using fallback provider due to primary failure');
          }
        }
      }
      
      const providerConfig = getProviderConfig(model);
      
      // Configure prompt based on provider capabilities
      const promptConfig: any = {
        name: 'generateTarotInterpretationRuntimePrompt', 
        input: { schema: GenerateTarotInterpretationInputSchema }, 
        prompt: promptTemplate, 
        model: model,
      };
      
      // Add provider-specific configuration
      if (providerConfig.supportsSafetySettings && safetySettings.length > 0) {
        promptConfig.config = {
          safetySettings: safetySettings,
        };
      }
      
      // For OpenAI models, we might need to adjust the prompt format
      if (providerConfig.provider === 'openai') {
        // OpenAI models work better with system messages
        // But since definePrompt doesn't support system messages directly,
        // we'll keep the prompt as is
      }

      console.log('[TAROT] Creating prompt with model:', model);
      const tarotPrompt = await ai.definePrompt(promptConfig);

      console.log('[TAROT] Calling AI with input:', {
        questionLength: input.question.length,
        cardSpread: input.cardSpread,
        cardsCount: input.cardInterpretations.split('\n').length,
        isGuestUser: input.isGuestUser
      });

      // Wrap the AI call with retry logic
      const llmResponse = await retryAICall(async () => {
        return await tarotPrompt(input);
      });
      const interpretationText = llmResponse.text; 

      if (!interpretationText) {
        console.error('[TAROT] AI í•´ì„ ìƒì„± ì‹¤íŒ¨: ìƒì„±ëœ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ì‘ë‹µ:', llmResponse);
        return { interpretation: 'AI í•´ì„ì„ ìƒì„±í•˜ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ìƒì„±ëœ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.' };
      }

      console.log('[TAROT] AI interpretation generated successfully, length:', interpretationText.length);
      
      // Cache the successful interpretation
      setCachedInterpretation(cacheKey, interpretationText);
      
      return { interpretation: interpretationText };

    } catch (e: any) {
      console.error('[TAROT] AI í”„ë¡¬í”„íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:', e);
      console.error('[TAROT] Error details:', {
        name: e.name,
        message: e.message,
        stack: e.stack,
        fullError: JSON.stringify(e, null, 2)
      });
      
      let userMessage = 'AI í•´ì„ ìƒì„± ì¤‘ ì¼ë°˜ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.';
      const errorMessage = e.toString();

      // Check for missing API key error
      if (errorMessage.includes('API key not found') || errorMessage.includes('Missing API key') || 
          errorMessage.includes('No AI provider plugins available') || e.message?.includes('No AI providers')) {
        userMessage = 'AI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê´€ë¦¬ì í˜ì´ì§€ì—ì„œ AI ì œê³µì—…ì²´ ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.';
      } else if (errorMessage.includes('429')) {
        userMessage = 'API ì‚¬ìš©ëŸ‰ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ê±°ë‚˜, ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì—¬ ì£¼ì„¸ìš”.';
      } else if (errorMessage.includes('503') || errorMessage.toLowerCase().includes('overloaded')) {
        userMessage = 'AI ëª¨ë¸ì— ëŒ€í•œ ìš”ì²­ì´ ë§ì•„ í˜„ì¬ ì‘ë‹µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.';
      } else if ((e as any).finishReason && (e as any).finishReason !== 'STOP') {
         userMessage = `AI ìƒì„±ì´ ì™„ë£Œë˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤ (ì´ìœ : ${(e as any).finishReason}). ì½˜í…ì¸  ì•ˆì „ ë¬¸ì œ ë˜ëŠ” ë‹¤ë¥¸ ì œì•½ ë•Œë¬¸ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. í”„ë¡¬í”„íŠ¸ë¥¼ ì¡°ì •í•˜ê±°ë‚˜ ì•ˆì „ ì„¤ì •ì„ í™•ì¸í•´ë³´ì„¸ìš”.`;
      } else if (errorMessage.includes("SAFETY")) {
         userMessage = "ìƒì„±ëœ ì½˜í…ì¸ ê°€ ì•ˆì „ ê¸°ì¤€ì— ë¶€í•©í•˜ì§€ ì•Šì•„ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. ì§ˆë¬¸ì´ë‚˜ í•´ì„ ìš”ì²­ ë‚´ìš©ì„ ìˆ˜ì •í•´ ë³´ì„¸ìš”.";
      } else if (errorMessage.includes("no valid candidates")) {
         userMessage = "AIê°€ í˜„ì¬ ìš”ì²­ì— ëŒ€í•´ ì ì ˆí•œ ë‹µë³€ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì§ˆë¬¸ì„ ì¡°ê¸ˆ ë‹¤ë¥´ê²Œ í•´ë³´ê±°ë‚˜, ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”. (No Valid Candidates)";
      } else {
        userMessage = `AI í•´ì„ ì˜¤ë¥˜: ${e.message || 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'}.`;
      }
      return { interpretation: userMessage };
    }
    }
  )(flowInput);
};
